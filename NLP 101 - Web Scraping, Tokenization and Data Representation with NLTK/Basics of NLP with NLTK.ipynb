{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP 101 - Web Scraping, Tokenization and Data Representation with NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "## Part 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "r = requests.get(url)\n",
    "html_text = r.text\n",
    "soup = BeautifulSoup(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stop = [x for x in sample.lower().split() if x not in stopword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d ={}\n",
    "for x in sample_stop:\n",
    "    if(x not in d.keys()):\n",
    "        d[x] = 1\n",
    "    else:\n",
    "        d[x] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_words = []\n",
    "stemmer = PorterStemmer()\n",
    "for x in list(d.keys()):\n",
    "    stem_words.append(stemmer.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_words = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for x in list(d.keys()):\n",
    "    lemmatize_words.append(lemmatizer.lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(d.keys())\n",
    "freq = list(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {\"Word\":words, \"Stemmed Word\":stem_words, \"Lemmatized Words\":lemmatize_words, \"Frequency\":freq}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Terms before stopword removal: 4621\n",
      "Total Terms after stopword removal: 3103\n",
      "Unique Stemmed Words: 1553\n",
      "Unique Lemmatized Word: 1679\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Stemmed Word</th>\n",
       "      <th>Lemmatized Words</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>natural</td>\n",
       "      <td>natur</td>\n",
       "      <td>natural</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>language</td>\n",
       "      <td>languag</td>\n",
       "      <td>language</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>processing</td>\n",
       "      <td>process</td>\n",
       "      <td>processing</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word Stemmed Word Lemmatized Words  Frequency\n",
       "0     natural        natur          natural         48\n",
       "1    language      languag         language         71\n",
       "2  processing      process       processing         21\n",
       "3           -            -                -          1\n",
       "4   wikipedia    wikipedia        wikipedia          3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total Terms before stopword removal:\",len(sample.split()))\n",
    "print(\"Total Terms after stopword removal:\",sum(freq))\n",
    "print(\"Unique Stemmed Words:\",len(list(set(stem_words))))\n",
    "print(\"Unique Lemmatized Word:\",len(list(set(lemmatize_words))))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword.append(\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stop = [x for x in sample.lower().split() if x not in stopword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d ={}\n",
    "for x in sample_stop:\n",
    "    if(x not in d.keys()):\n",
    "        d[x] = 1\n",
    "    else:\n",
    "        d[x] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(d.keys())\n",
    "freq = list(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {\"Word\":words, \"Frequency\":freq}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Terms before stopword removal: 4621\n",
      "Total Terms after stopword removal: 3032\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>natural</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>processing</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>wikipedia,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  Frequency\n",
       "0     natural         48\n",
       "1  processing         21\n",
       "2           -          1\n",
       "3   wikipedia          3\n",
       "4  wikipedia,          1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total Terms before stopword removal:\",len(sample.split()))\n",
    "print(\"Total Terms after stopword removal:\",sum(freq))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_words = [x for x in stopword if x in sample.lower().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_words_pos = pos_tag(removed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " ('you', 'PRP'),\n",
       " ('your', 'PRP$'),\n",
       " ('it', 'PRP'),\n",
       " ('its', 'PRP$'),\n",
       " ('they', 'PRP'),\n",
       " ('their', 'PRP$'),\n",
       " ('what', 'WP'),\n",
       " ('which', 'WDT'),\n",
       " ('who', 'WP'),\n",
       " ('this', 'DT'),\n",
       " ('that', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('those', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('are', 'VBP'),\n",
       " ('was', 'VBD'),\n",
       " ('were', 'VBD'),\n",
       " ('be', 'VB'),\n",
       " ('been', 'VBN'),\n",
       " ('being', 'VBG'),\n",
       " ('have', 'VB'),\n",
       " ('has', 'VBZ'),\n",
       " ('had', 'VBN'),\n",
       " ('do', 'RP'),\n",
       " ('a', 'DT'),\n",
       " ('an', 'DT'),\n",
       " ('the', 'DT'),\n",
       " ('and', 'CC'),\n",
       " ('but', 'CC'),\n",
       " ('if', 'IN'),\n",
       " ('or', 'CC'),\n",
       " ('because', 'IN'),\n",
       " ('as', 'IN'),\n",
       " ('until', 'IN'),\n",
       " ('while', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('at', 'IN'),\n",
       " ('by', 'IN'),\n",
       " ('for', 'IN'),\n",
       " ('with', 'IN'),\n",
       " ('about', 'NN'),\n",
       " ('between', 'IN'),\n",
       " ('into', 'IN'),\n",
       " ('through', 'IN'),\n",
       " ('during', 'IN'),\n",
       " ('before', 'RB'),\n",
       " ('after', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('from', 'IN'),\n",
       " ('up', 'RP'),\n",
       " ('in', 'IN'),\n",
       " ('out', 'RP'),\n",
       " ('on', 'IN'),\n",
       " ('over', 'IN'),\n",
       " ('under', 'IN'),\n",
       " ('further', 'JJ'),\n",
       " ('then', 'RB'),\n",
       " ('there', 'EX'),\n",
       " ('when', 'WRB'),\n",
       " ('where', 'WRB'),\n",
       " ('how', 'WRB'),\n",
       " ('all', 'DT'),\n",
       " ('any', 'DT'),\n",
       " ('both', 'DT'),\n",
       " ('each', 'DT'),\n",
       " ('more', 'JJR'),\n",
       " ('most', 'RBS'),\n",
       " ('other', 'JJ'),\n",
       " ('some', 'DT'),\n",
       " ('such', 'JJ'),\n",
       " ('no', 'DT'),\n",
       " ('not', 'RB'),\n",
       " ('only', 'RB'),\n",
       " ('same', 'JJ'),\n",
       " ('so', 'RB'),\n",
       " ('than', 'IN'),\n",
       " ('very', 'RB'),\n",
       " ('t', 'JJ'),\n",
       " ('can', 'MD'),\n",
       " ('will', 'MD'),\n",
       " ('should', 'MD'),\n",
       " ('now', 'RB'),\n",
       " ('d', 'VB'),\n",
       " ('m', 'NN'),\n",
       " ('o', 'JJ'),\n",
       " ('language', 'NN')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_words_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Doc 1</th>\n",
       "      <th>Doc 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>outputs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>model.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>representation.\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>function</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>door\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Doc 1  Doc 2\n",
       "0           outputs      0      1\n",
       "1            model.      0      1\n",
       "2  representation.\"      0      1\n",
       "3          function      1      1\n",
       "4             door\"      1      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import io\n",
    "url_1 = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "url_2 = \"https://en.wikipedia.org/wiki/Machine_learning\"\n",
    "r = requests.get(url_1)\n",
    "html_text = r.text\n",
    "soup = BeautifulSoup(html_text)\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()\n",
    "content_1 = soup.get_text()\n",
    "r = requests.get(url_2)\n",
    "html_text = r.text\n",
    "soup = BeautifulSoup(html_text)\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()\n",
    "content_2 = soup.get_text()\n",
    "with io.open('nlp.doc', mode = 'w+',encoding=\"utf-8\") as file_1:\n",
    "    file_1.write(content_1)\n",
    "with io.open('ml.doc', mode = 'w+',encoding=\"utf-8\") as file_2:\n",
    "    file_2.write(content_2)\n",
    "stopword = stopwords.words(\"english\")\n",
    "content_1_stop = [x for x in content_1.lower().split() if x not in stopword]\n",
    "content_2_stop = [x for x in content_2.lower().split() if x not in stopword]\n",
    "all_words = content_1_stop + content_2_stop\n",
    "all_words = list(set(all_words))\n",
    "bool_1 = []\n",
    "bool_2 = []\n",
    "for x in all_words:\n",
    "    if x in content_1_stop:\n",
    "        bool_1.append(1)\n",
    "    else:\n",
    "        bool_1.append(0)\n",
    "    if x in content_2_stop:\n",
    "        bool_2.append(1)\n",
    "    else:\n",
    "        bool_2.append(0)\n",
    "final_dict = {\"Word\":all_words, \"Doc 1\":bool_1, \"Doc 2\":bool_2}\n",
    "df = pd.DataFrame(final_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter query:function\n",
      "Presence of \"function\" in Doc 1: 1\n",
      "Presence of \"function\" in Doc 2: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Freq in Doc 1</th>\n",
       "      <th>Freq in Doc 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>outputs</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>model.</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>representation.\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>function</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>door\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4574</td>\n",
       "      <td>observed</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4575</td>\n",
       "      <td>developed</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4576</td>\n",
       "      <td>contain</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4577</td>\n",
       "      <td>at&amp;t</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4578</td>\n",
       "      <td>978-1848219212.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4579 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word  Freq in Doc 1  Freq in Doc 2\n",
       "0              outputs              0              3\n",
       "1               model.              0              3\n",
       "2     representation.\"              0              1\n",
       "3             function              1              6\n",
       "4                door\"              1              0\n",
       "...                ...            ...            ...\n",
       "4574          observed              0              2\n",
       "4575         developed              2              1\n",
       "4576           contain              0              4\n",
       "4577              at&t              0              1\n",
       "4578   978-1848219212.              1              0\n",
       "\n",
       "[4579 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=input(\"Enter query:\")\n",
    "for q in query.lower().split():\n",
    "    try:\n",
    "        f1=df['Doc 1'][all_words.index(q)]\n",
    "        print(\"Presence of \\\"\"+ query +\"\\\" in Doc 1:\",f1)\n",
    "    except ValueError:\n",
    "        print(\"Presence of \\\"\" + query + \"\\\" in Doc 1:\",0)\n",
    "    try:\n",
    "        f2=df['Doc 2'][all_words.index(q)]\n",
    "        print(\"Presence of \\\"\"+ query +\"\\\" in Doc 2:\",f2)\n",
    "    except ValueError:\n",
    "        print(\"Presence of \\\"\" + query + \"\\\" in Doc 2:\",0)\n",
    "d1 = {}\n",
    "d2 = {}\n",
    "for x in all_words:\n",
    "        if x in content_1_stop:\n",
    "            for y in content_1_stop:\n",
    "                if x == y:\n",
    "                    if x not in d1.keys():\n",
    "                        d1[x] = 1\n",
    "                    else:\n",
    "                        d1[x] += 1\n",
    "        else:\n",
    "            d1[x] = 0\n",
    "        if x in content_2_stop:\n",
    "            for y in content_2_stop:\n",
    "                if x == y:\n",
    "                    if x not in d2.keys():\n",
    "                        d2[x] = 1\n",
    "                    else:\n",
    "                        d2[x] += 1\n",
    "        else:\n",
    "            d2[x] = 0\n",
    "final_dict = {\"Word\":all_words, \"Freq in Doc 1\": list(d1.values()), \"Freq in Doc 2\": list(d2.values())}\n",
    "df = pd.DataFrame(final_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>function</td>\n",
       "      <td>2152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>door\"</td>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"why</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>opposite</td>\n",
       "      <td>1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>earliest-used</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Position\n",
       "0       function      2152\n",
       "1          door\"      1703\n",
       "2           \"why       241\n",
       "3       opposite      1775\n",
       "4  earliest-used       341"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = []\n",
    "pos = []\n",
    "for x in all_words:\n",
    "    i = 0\n",
    "    if x in content_1_stop:\n",
    "        for y in content_1_stop:\n",
    "            i += 1\n",
    "            if x == y:\n",
    "                word.append(x)\n",
    "                pos.append(content_1_stop.index(x,i-1))\n",
    "final_dict = {\"Word\":word, \"Position\":pos}\n",
    "df = pd.DataFrame(final_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>outputs</td>\n",
       "      <td>1553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>outputs</td>\n",
       "      <td>1572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>outputs</td>\n",
       "      <td>1580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>model.</td>\n",
       "      <td>2517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>model.</td>\n",
       "      <td>3622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Position\n",
       "0  outputs      1553\n",
       "1  outputs      1572\n",
       "2  outputs      1580\n",
       "3   model.      2517\n",
       "4   model.      3622"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = []\n",
    "pos = []\n",
    "for x in all_words:\n",
    "    i = 0\n",
    "    if x in content_2_stop:\n",
    "        for y in content_2_stop:\n",
    "            i += 1\n",
    "            if x == y:\n",
    "                word.append(x)\n",
    "                pos.append(content_2_stop.index(x,i-1))\n",
    "final_dict = {\"Word\":word, \"Position\":pos}\n",
    "df = pd.DataFrame(final_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thankyou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
